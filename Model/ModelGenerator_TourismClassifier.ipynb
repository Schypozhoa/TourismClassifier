{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1pRwNULAK1r8J0n_iz5zHwuQvioFDsHBE",
      "authorship_tag": "ABX9TyMoK+J3YE3rURoQk1wiRTBY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Schypozhoa/TourismClassifier/blob/master/Model/ModelGenerator_TourismClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMPORT ALL NEEDED MODULE"
      ],
      "metadata": {
        "id": "qOIB98U4CGff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import losses\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "_Zn6Be7HCBLL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Dataset in Local Environment"
      ],
      "metadata": {
        "id": "MaudsCEYCMvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def splitDataset(originalPath, ratio, savedPath, splitted):\n",
        "    # Check if the originalPath folder exist or not\n",
        "    if not os.path.exists(originalPath):\n",
        "        raise Exception(\"OriginalPath folder not found, please check the path\")\n",
        "\n",
        "    # Check if the savedPath folder exist or not\n",
        "    if not os.path.exists(savedPath):\n",
        "        os.makedirs(savedPath)\n",
        "    elif splitted:\n",
        "        return os.path.join(savedPath, \"train\"), os.path.join(savedPath, \"test\")\n",
        "    else:\n",
        "        raise Exception(\"\"\"SavedPath folder already exist and ALREADY_SPLITTED = FALSE, \n",
        "                        please choose another folder or change the ALREADY_SPLITTED variable to TRUE if you want to use the existing folder\"\"\")\n",
        "    \n",
        "    # Create train and test folder\n",
        "    trainPath = os.path.join(savedPath, \"train\")\n",
        "    testPath = os.path.join(savedPath, \"test\")\n",
        "    if not os.path.exists(trainPath):\n",
        "        os.makedirs(trainPath)\n",
        "    if not os.path.exists(testPath):\n",
        "        os.makedirs(testPath)\n",
        "\n",
        "    # Get all the class name from the originalPath folder and create the folder in train and test folder\n",
        "    classes = os.listdir(originalPath)\n",
        "    for className in classes:\n",
        "        className = className[7:]\n",
        "        trainClassPath = os.path.join(trainPath, className)\n",
        "        testClassPath = os.path.join(testPath, className)\n",
        "        if not os.path.exists(trainClassPath):\n",
        "            os.makedirs(trainClassPath)\n",
        "        if not os.path.exists(testClassPath):\n",
        "            os.makedirs(testClassPath)\n",
        "\n",
        "    # Split the dataset and keep the copy in the originalPath folder\n",
        "    for className in classes:\n",
        "        classNameOriginal = className\n",
        "        className = className[7:]\n",
        "        classPathOriginal = os.path.join(originalPath, classNameOriginal)\n",
        "        trainClassPath = os.path.join(trainPath, className)\n",
        "        testClassPath = os.path.join(testPath, className)\n",
        "        images = os.listdir(classPathOriginal)\n",
        "        trainImages = images[:int(len(images)*ratio)]\n",
        "        testImages = images[int(len(images)*ratio):]\n",
        "        for image in trainImages:\n",
        "            shutil.copy(os.path.join(classPathOriginal, image), os.path.join(trainClassPath, image))\n",
        "        for image in testImages:\n",
        "            shutil.copy(os.path.join(classPathOriginal, image), os.path.join(testClassPath, image))\n",
        "\n",
        "    return trainPath, testPath"
      ],
      "metadata": {
        "id": "wO3j29s9CFM7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Dataset in Colab"
      ],
      "metadata": {
        "id": "JKYPeTWyCUVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/Schypozhoa/TourismClassifier/raw/master/Data/AttractionDataset-Splitted.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQfvqNF8Dffh",
        "outputId": "ae083aef-5731-47e8-e2ac-948cbf38e05c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-24 14:20:39--  https://github.com/Schypozhoa/TourismClassifier/raw/master/Data/AttractionDataset-Splitted.zip\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Schypozhoa/TourismClassifier/master/Data/AttractionDataset-Splitted.zip [following]\n",
            "--2023-05-24 14:20:39--  https://raw.githubusercontent.com/Schypozhoa/TourismClassifier/master/Data/AttractionDataset-Splitted.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31058170 (30M) [application/zip]\n",
            "Saving to: ‘AttractionDataset-Splitted.zip’\n",
            "\n",
            "AttractionDataset-S 100%[===================>]  29.62M   138MB/s    in 0.2s    \n",
            "\n",
            "2023-05-24 14:20:41 (138 MB/s) - ‘AttractionDataset-Splitted.zip’ saved [31058170/31058170]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/AttractionDataset-Splitted.zip\""
      ],
      "metadata": {
        "id": "lEJn-f6EHEEB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extractDataset():\n",
        "    train = \"/content/AttractionDataset-Splitted/train\"\n",
        "    val = \"/content/AttractionDataset-Splitted/test\"\n",
        "    return train, val"
      ],
      "metadata": {
        "id": "L0kCS-Q-CYjV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the model"
      ],
      "metadata": {
        "id": "tFbAgCfGC6xO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def createModel(optimizer, loss):\n",
        "    # Define the pretrained model\n",
        "    pretrainedModel = tf.keras.applications.VGG19(weights='imagenet', \n",
        "                                                  include_top=False, \n",
        "                                                  input_shape=(300, 300, 3))\n",
        "    pretrainedModel.trainable = False\n",
        "\n",
        "    # Create the model\n",
        "    model = models.Sequential([ \n",
        "        pretrainedModel,\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(16, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss,\n",
        "        metrics=['accuracy']\n",
        "        ) \n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "32pc2AVdCfjJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess and augment the Train and Validation Generator"
      ],
      "metadata": {
        "id": "md5AVhLeC0jb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainValGen(trainPath, valPath):\n",
        "    # Do data augmentation for train data and prepare validation data\n",
        "    trainDatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='reflect')\n",
        "\n",
        "    valDatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        )\n",
        "    \n",
        "    trainGenerator = trainDatagen.flow_from_directory(\n",
        "        directory=trainPath,\n",
        "        batch_size=25,\n",
        "        class_mode='categorical',\n",
        "        target_size=(300, 300)\n",
        "        )\n",
        "    \n",
        "    valGenerator = valDatagen.flow_from_directory(\n",
        "        directory=valPath,\n",
        "        batch_size=25,\n",
        "        class_mode='categorical',\n",
        "        target_size=(300, 300)\n",
        "        )\n",
        "\n",
        "    return trainGenerator, valGenerator"
      ],
      "metadata": {
        "id": "pmEzlktHB-Zx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot the accuracy"
      ],
      "metadata": {
        "id": "m-9t0Q7kCwy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotHistory(history):\n",
        "    acc=history.history['accuracy']\n",
        "    val_acc=history.history['val_accuracy']\n",
        "    loss=history.history['loss']\n",
        "    val_loss=history.history['val_loss']\n",
        "\n",
        "    epochs=range(len(acc))\n",
        "\n",
        "    plt.plot(epochs, acc, 'r', \"Train Acc\")\n",
        "    plt.plot(epochs, val_acc, 'b', \"Val Acc\")\n",
        "    plt.title('TrainVal accuracy')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(epochs, loss, 'r', \"Train Loss\")\n",
        "    plt.plot(epochs, val_loss, 'b', \"Val Loss\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "pOq5PMbvCwM7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess the prediction data"
      ],
      "metadata": {
        "id": "UbeIz8efCmtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predGen(predPath):\n",
        "    # Prepare the prediction data\n",
        "    predDatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        )\n",
        "    \n",
        "    predGenerator = predDatagen.flow_from_directory(\n",
        "        directory=predPath,\n",
        "        class_mode=None,\n",
        "        target_size=(300, 300)\n",
        "        )\n",
        "    \n",
        "    return predGenerator"
      ],
      "metadata": {
        "id": "3dB_Kh0oChtv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Pipeline"
      ],
      "metadata": {
        "id": "8YOjQVYkCrMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kalo di colab, tinggal ganti ON_COLAB = True"
      ],
      "metadata": {
        "id": "vPnV5-hEHrn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable for dataset, splitted = dataset with train and test folder\n",
        "DATASET_PATH = \"C:/Users/Administrator/Desktop/Capstone/Data/AttractionDataset/\"\n",
        "SPLITTED_PATH = \"C:/Users/Administrator/Desktop/Capstone/Data/AttractionDataset-Splitted/\"\n",
        "PREDICTION_PATH = \"\"\n",
        "RATIO = 0.8\n",
        "ALREADY_SPLITTED = True\n",
        "ON_COLAB = True\n",
        "\n",
        "# Prepare the dataset\n",
        "if not ON_COLAB:\n",
        "    trainPath, valPath = splitDataset(DATASET_PATH, RATIO, SPLITTED_PATH, ALREADY_SPLITTED)\n",
        "else:\n",
        "    trainPath, valPath = extractDataset()\n",
        "trainGen, valGen = trainValGen(trainPath, valPath)\n",
        "\n",
        "# Show images from the trainGen ImageDataGenerator using matplotlib\n",
        "# NUM_IMAGES = 25\n",
        "# x, y = trainGen.next()\n",
        "# fig = plt.figure(figsize=(10, 10))\n",
        "# for i in range(0, NUM_IMAGES):\n",
        "#     image = x[i]\n",
        "#     fig.add_subplot(5, 5, i+1)\n",
        "#     plt.imshow(image)\n",
        "# plt.show()\n",
        "\n",
        "# Show 1 sample images from the trainGen ImageDataGenerator using matplotlib\n",
        "# x, y = trainGen.next()\n",
        "# image = x[0]\n",
        "# plt.imshow(image)\n",
        "# plt.show()\n",
        "\n",
        "# Variable for the model\n",
        "LEARNING_RATE = 0.001\n",
        "OPTIMIZER = optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "LOSS = losses.CategoricalCrossentropy()\n",
        "SAVED_MODEL_PATH = \"C:/Users/Administrator/Desktop/Capstone/Model/testVGG19.h5\"\n",
        "SAVED_MODEL_PATH_COLAB = \"/content/testVGG19.h5\"\n",
        "\n",
        "# Create the model\n",
        "model = createModel(OPTIMIZER, LOSS)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    trainGen, \n",
        "    epochs=10, \n",
        "    validation_data=valGen, \n",
        "    verbose=1\n",
        "    )\n",
        "\n",
        "# Save and plot the model\n",
        "if not ON_COLAB:\n",
        "  model.save(SAVED_MODEL_PATH)\n",
        "else:\n",
        "  model.save(SAVED_MODEL_PATH_COLAB)\n",
        "plotHistory(history)\n",
        "\n",
        "# This code is for testing the prediction using saved model\n",
        "\n",
        "# model = tf.keras.saving.load_model(\"C:/Users/Administrator/Desktop/Capstone/Model/Test.h5\")\n",
        "# res = model.predict(predGen)\n",
        "# lab = list(trainGen.class_indices.keys())\n",
        "# sel = res.argmax(axis=1)\n",
        "# print(res)\n",
        "# print(predGen.filenames)\n",
        "# print(f\"Predicted class: {lab[sel[0]]}, with probability {res[0][sel[0]]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKTfaMZQClI-",
        "outputId": "fe0398cb-bba4-49e2-eee4-1ad98e75325e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2108 images belonging to 16 classes.\n",
            "Found 535 images belonging to 16 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "85/85 [==============================] - 76s 720ms/step - loss: 4.5810 - accuracy: 0.1921 - val_loss: 2.2400 - val_accuracy: 0.2897\n",
            "Epoch 2/10\n",
            "85/85 [==============================] - 57s 673ms/step - loss: 2.1643 - accuracy: 0.3226 - val_loss: 1.9731 - val_accuracy: 0.3645\n",
            "Epoch 3/10\n",
            "85/85 [==============================] - 57s 674ms/step - loss: 2.0623 - accuracy: 0.3662 - val_loss: 1.9275 - val_accuracy: 0.4093\n",
            "Epoch 4/10\n",
            "85/85 [==============================] - 58s 676ms/step - loss: 2.0120 - accuracy: 0.3639 - val_loss: 1.9192 - val_accuracy: 0.4131\n",
            "Epoch 5/10\n"
          ]
        }
      ]
    }
  ]
}